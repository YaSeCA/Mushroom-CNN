{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "'''\n",
    "Sequential : Sert à initialiser un modèle de réseau de neurones en tant que réseau séquentiel. \n",
    "'''\n",
    "from keras.models import Sequential\n",
    "'''\n",
    "Conv2D : Sert à effectuer l'opération de convolution (la première étape du CNN) en 2D vue que l'on\n",
    "travail sur des images.\n",
    "'''\n",
    "from keras.layers import Conv2D\n",
    "'''\n",
    "MaxPooling2D : Sert à l'opération de Pooling (étape 2 du CNN). \n",
    "MaxPooling sera utilisé, car nous avons besoin du pixel de valeur maximale de la région d'intérêt.\n",
    "'''\n",
    "from keras.layers import MaxPooling2D\n",
    "'''\n",
    "Flatten : Sert à l'aplatissement pour  la conversion de tous les tableaux bidimensionnels résultants en un seul \n",
    "vecteur linéaire.\n",
    "'''\n",
    "from keras.layers import Flatten\n",
    "'''\n",
    "Dense : Sert à effectuer la connexion complète du réseau de neurones (étape 4 du CNN).\n",
    "'''\n",
    "from keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separe l'ensemble des champignons en 2 groupes - Le groupe d'entrainement et de test\n",
    "#Soit n, le total de champignons pour un type donne de champignon\n",
    "#passer l'argument'nombre_images_entrainement' avec une valeur x\n",
    "#engendrera 2 repertoires, le premier contenant un repertoir pour chaque type de champignon.\n",
    "#Chacun de ces repertoires contient x champignons. Pour l'entrainement du CNN.\n",
    "#Puis un deuxieme repertoir contenant un reprtoir pour chaque type de champignon.\n",
    "#Chacun de ces repertoires contient y = n - x champignons. Pour tester le CNN.\n",
    "\n",
    "directory_name = \"Champignons\"\n",
    "\n",
    "def creer_fichier ( nombre_images_entrainement):\n",
    "\n",
    "    entrainement = \"entrainement\"\n",
    "    tests = \"tests\"\n",
    "    \n",
    "    shutil.rmtree(entrainement)\n",
    "    shutil.rmtree(tests)\n",
    "\n",
    "    os.mkdir(entrainement)\n",
    "    os.mkdir(tests)\n",
    "\n",
    "    for filename in os.listdir(directory_name):\n",
    "        f = os.path.join(directory_name, filename)\n",
    "\n",
    "        i = 0\n",
    "        middle = f.split(\"/\")[1]\n",
    "        os.mkdir(entrainement + \"/\" + middle)\n",
    "        os.mkdir(tests + \"/\" + middle)\n",
    "\n",
    "        for subfilename in os.listdir(f):\n",
    "            subf = os.path.join(f, subfilename)\n",
    "            if (i < nombre_images_entrainement):\n",
    "                copyfile(subf, entrainement + \"/\" + middle + \"/\" + subf.split(\"/\")[2])\n",
    "            else:\n",
    "                copyfile(subf, tests + \"/\" + middle + \"/\" + subf.split(\"/\")[2])\n",
    "\n",
    "            i=i+1\n",
    "\n",
    "creer_fichier(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6673/1220530848.py:40: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  modele.fit_generator(entrainement,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 12s 454ms/step - loss: 2.4020 - accuracy: 0.0925 - val_loss: 2.2862 - val_accuracy: 0.1050\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 11s 437ms/step - loss: 2.2899 - accuracy: 0.1200 - val_loss: 2.2641 - val_accuracy: 0.1600\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 10s 410ms/step - loss: 2.2697 - accuracy: 0.1688 - val_loss: 2.2567 - val_accuracy: 0.1700\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 11s 442ms/step - loss: 2.2310 - accuracy: 0.1850 - val_loss: 2.2168 - val_accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 11s 454ms/step - loss: 2.1576 - accuracy: 0.2200 - val_loss: 2.1904 - val_accuracy: 0.1950\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 11s 454ms/step - loss: 2.0662 - accuracy: 0.2587 - val_loss: 2.0569 - val_accuracy: 0.2350\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 11s 449ms/step - loss: 1.9731 - accuracy: 0.2937 - val_loss: 2.1302 - val_accuracy: 0.2550\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 10s 420ms/step - loss: 1.8566 - accuracy: 0.3200 - val_loss: 2.0375 - val_accuracy: 0.3050\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 11s 438ms/step - loss: 1.8095 - accuracy: 0.3550 - val_loss: 2.0744 - val_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 11s 438ms/step - loss: 1.6713 - accuracy: 0.4238 - val_loss: 2.1410 - val_accuracy: 0.2950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f314d2a3c10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instancie un CNN sequentiel\n",
    "modele = Sequential()\n",
    "\n",
    "#Etape de Convolution avec ReLU\n",
    "modele.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "#Pooling \n",
    "modele.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Flattering\n",
    "modele.add(Flatten())\n",
    "\n",
    "#1 couche cache avec 128 neurones\n",
    "modele.add(Dense(units = 128, activation = 'relu'))\n",
    "modele.add(Dense(units = 128, activation = 'relu'))\n",
    "modele.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "#Neurone de sortie avec fct d'activation softmax\n",
    "modele.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "#Compilation du modele avec optimizer adam\n",
    "modele.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Pre-processing des image pour eviter l'over-fitting\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2, \n",
    "horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255) \n",
    "entrainement = train_datagen.flow_from_directory('entrainement',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "tests = test_datagen.flow_from_directory('tests',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "\n",
    "#Apprentissage du modele\n",
    "modele.fit_generator(entrainement,\n",
    "epochs = 10,\n",
    "validation_data = tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 250ms/step - loss: 2.1410 - accuracy: 0.2950\n",
      "2.1410303115844727\n",
      "0.29499998688697815\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = modele.evaluate(tests)\n",
    "\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6673/1959354757.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn.modele'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('cnn.modele')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
